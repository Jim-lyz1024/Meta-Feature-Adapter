# Meta-Feature Adapter: Integrating Environmental Metadata for Enhanced Animal Re-identification

## Abstract
Reliable identification of individual animals within large wildlife populations is crucial for effective conservation efforts.
Recently, computer vision techniques have presented promising results in animal re-identification (Animal ReID) by leveraging data from camera traps. However, current methods rely solely on visual data, overlooking environmental metadata that ecologists have identified as highly correlated with animal behavior and identity, such as temperature and circadian rhythms. To bridge this gap, we propose the Meta-Feature Adapter (MFA), a lightweight module designed to integrate environmental metadata into vision-language foundation models like CLIP, enhancing performance in Animal ReID tasks. MFA introduces a novel metadata-aware text embedding strategy, which translates environmental metadata into natural language descriptions and incorporates them into image features via a cross-attention mechanism. Additionally, we leverage a Gated Cross-Attention mechanism that dynamically adjusts metadata weights, further boosting performance. To validate our approach, we constructed the Metadata Augmented Animal Re-identification (MAAR) dataset, encompassing six species from New Zealand and featuring paired image data and environmental metadata. Extensive experiments demonstrate that MFA consistently improves Animal ReID performance across multiple baseline models.